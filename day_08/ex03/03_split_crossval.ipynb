{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 08. Exercise 03\n",
    "# Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`.\n",
    "3. Using, for example, `value_counts()` to check if the distribution of classes is similar in train and test.\n",
    "4. Use the additional parameter `stratify=` and check the distribution again, now it should be more or less similar in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1686 entries, 0 to 1685\n",
      "Data columns (total 44 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   numTrials         1686 non-null   float64\n",
      " 1   hour              1686 non-null   float64\n",
      " 2   dayofweek         1686 non-null   int64  \n",
      " 3   uid_user_0        1686 non-null   float64\n",
      " 4   uid_user_1        1686 non-null   float64\n",
      " 5   uid_user_10       1686 non-null   float64\n",
      " 6   uid_user_11       1686 non-null   float64\n",
      " 7   uid_user_12       1686 non-null   float64\n",
      " 8   uid_user_13       1686 non-null   float64\n",
      " 9   uid_user_14       1686 non-null   float64\n",
      " 10  uid_user_15       1686 non-null   float64\n",
      " 11  uid_user_16       1686 non-null   float64\n",
      " 12  uid_user_17       1686 non-null   float64\n",
      " 13  uid_user_18       1686 non-null   float64\n",
      " 14  uid_user_19       1686 non-null   float64\n",
      " 15  uid_user_2        1686 non-null   float64\n",
      " 16  uid_user_20       1686 non-null   float64\n",
      " 17  uid_user_21       1686 non-null   float64\n",
      " 18  uid_user_22       1686 non-null   float64\n",
      " 19  uid_user_23       1686 non-null   float64\n",
      " 20  uid_user_24       1686 non-null   float64\n",
      " 21  uid_user_25       1686 non-null   float64\n",
      " 22  uid_user_26       1686 non-null   float64\n",
      " 23  uid_user_27       1686 non-null   float64\n",
      " 24  uid_user_28       1686 non-null   float64\n",
      " 25  uid_user_29       1686 non-null   float64\n",
      " 26  uid_user_3        1686 non-null   float64\n",
      " 27  uid_user_30       1686 non-null   float64\n",
      " 28  uid_user_31       1686 non-null   float64\n",
      " 29  uid_user_4        1686 non-null   float64\n",
      " 30  uid_user_6        1686 non-null   float64\n",
      " 31  uid_user_7        1686 non-null   float64\n",
      " 32  uid_user_8        1686 non-null   float64\n",
      " 33  labname_code_rvw  1686 non-null   float64\n",
      " 34  labname_lab02     1686 non-null   float64\n",
      " 35  labname_lab03     1686 non-null   float64\n",
      " 36  labname_lab03s    1686 non-null   float64\n",
      " 37  labname_lab05s    1686 non-null   float64\n",
      " 38  labname_laba04    1686 non-null   float64\n",
      " 39  labname_laba04s   1686 non-null   float64\n",
      " 40  labname_laba05    1686 non-null   float64\n",
      " 41  labname_laba06    1686 non-null   float64\n",
      " 42  labname_laba06s   1686 non-null   float64\n",
      " 43  labname_project1  1686 non-null   float64\n",
      "dtypes: float64(43), int64(1)\n",
      "memory usage: 579.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4         0.0         0.0          0.0   \n",
       "1     -0.756764 -2.562352          4         0.0         0.0          0.0   \n",
       "2     -0.724861 -2.562352          4         0.0         0.0          0.0   \n",
       "3     -0.692958 -2.562352          4         0.0         0.0          0.0   \n",
       "4     -0.661055 -2.562352          4         0.0         0.0          0.0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3         0.0         0.0          0.0   \n",
       "1682  -0.629151  0.945382          3         0.0         1.0          0.0   \n",
       "1683  -0.597248  0.945382          3         0.0         1.0          0.0   \n",
       "1684  -0.565345  0.945382          3         0.0         1.0          0.0   \n",
       "1685  -0.533442  0.945382          3         0.0         1.0          0.0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "2             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "3             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "4             0.0          0.0          0.0          0.0  ...            0.0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1682          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1683          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1684          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "1685          0.0          0.0          0.0          0.0  ...            0.0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0               0.0             0.0             0.0             0.0   \n",
       "1               0.0             0.0             0.0             0.0   \n",
       "2               0.0             0.0             0.0             0.0   \n",
       "3               0.0             0.0             0.0             0.0   \n",
       "4               0.0             0.0             0.0             0.0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681            0.0             0.0             0.0             0.0   \n",
       "1682            0.0             0.0             0.0             0.0   \n",
       "1683            0.0             0.0             0.0             0.0   \n",
       "1684            0.0             0.0             0.0             0.0   \n",
       "1685            0.0             0.0             0.0             0.0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                 0.0             0.0             0.0              0.0   \n",
       "1                 0.0             0.0             0.0              0.0   \n",
       "2                 0.0             0.0             0.0              0.0   \n",
       "3                 0.0             0.0             0.0              0.0   \n",
       "4                 0.0             0.0             0.0              0.0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681              0.0             0.0             0.0              1.0   \n",
       "1682              0.0             0.0             0.0              1.0   \n",
       "1683              0.0             0.0             0.0              1.0   \n",
       "1684              0.0             0.0             0.0              1.0   \n",
       "1685              0.0             0.0             0.0              1.0   \n",
       "\n",
       "      labname_project1  \n",
       "0                  1.0  \n",
       "1                  1.0  \n",
       "2                  1.0  \n",
       "3                  1.0  \n",
       "4                  1.0  \n",
       "...                ...  \n",
       "1681               0.0  \n",
       "1682               0.0  \n",
       "1683               0.0  \n",
       "1684               0.0  \n",
       "1685               0.0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/dayofweek.csv\")\n",
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"dayofweek\"]\n",
    "features = df.drop(columns=[\"dayofweek\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.295238\n",
       "1    0.234234\n",
       "2    0.192000\n",
       "3    0.265176\n",
       "4    0.300000\n",
       "5    0.254630\n",
       "6    0.240418\n",
       "Name: dayofweek, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "y_test.value_counts() / y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.253165\n",
       "6    0.249123\n",
       "1    0.251142\n",
       "5    0.248848\n",
       "2    0.252101\n",
       "0    0.247706\n",
       "4    0.253012\n",
       "Name: dayofweek, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, \n",
    "                                                    random_state=21, stratify=target)\n",
    "y_test.value_counts() / y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train exactly the same baseline models from the previous exercise and calculate the accuracies using the test dataset with stratification.\n",
    "2. Did all the models show the similar values of the metric? Which one has the largest difference comparing the current exercise and the previous? Put the answer to the markdown cell in the end of the section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6272189349112426"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=21, fit_intercept=False)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7159763313609467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(random_state=21, probability=True, kernel=\"linear\")\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5295857988165681"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=4, random_state=21)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289940828402367"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth = 25, random_state=21)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Crossvalidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could play with parameters of the model trying to achive a better accuracy on the test dataset, but it is a bad practice. It leads us again to overfitting. Test dataset is only for checking quality of a final model.\n",
    "\n",
    "But there is another way of solving the problem – crossvalidation. It does not use test dataset, but creates one more split of train dataset. Again, there are different ways of doing it, but the common thing is that there is a validation dataset that is used for hyperparameters optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using `cross_val_score` with `cv=10` calculate the mean accuracy and standard deviation for every model that you used before (logreg with `solver='liblinear'`, SVC, decision tree, random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=21, fit_intercept=False, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.45291983657368284\n",
      "std 0.16960708432126997\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model, features, target, scoring=\"accuracy\", cv=10)\n",
    "print(\"mean\", scores.mean())\n",
    "print(\"std\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.5051986475063398\n",
      "std 0.15857963555262297\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(random_state=21, probability=True, kernel=\"linear\")\n",
    "scores = cross_val_score(model, features, target, scoring=\"accuracy\", cv=10)\n",
    "print(\"mean\", scores.mean())\n",
    "print(\"std\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.3883523527754297\n",
      "std 0.11835394295385691\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=4, random_state=21)\n",
    "scores = cross_val_score(model, features, target, scoring=\"accuracy\", cv=10)\n",
    "print(\"mean\", scores.mean())\n",
    "print(\"std\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.6607847280924204\n",
      "std 0.17462799234675505\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth = 25, random_state=21)\n",
    "scores = cross_val_score(model, features, target, scoring=\"accuracy\", cv=10)\n",
    "print(\"mean\", scores.mean())\n",
    "print(\"std\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and play a little bit with the parameters on cross-validation, find a good enough parameter or a combination of the parameters.\n",
    "2. Calculate the accuracy for the final model on the test dataset.\n",
    "3. Draw a plot that displays the top-10 most  important features for that model.\n",
    "4. Save the model using `joblib`.\n",
    "5. Load the model, make predictions for the test dataset and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators:  1  max_depth:  1 score:  0.22895886165116935\n",
      "n_estimators:  1  max_depth:  10 score:  0.3622464074387151\n",
      "n_estimators:  1  max_depth:  50 score:  0.36403212172442945\n",
      "n_estimators:  1  max_depth:  100 score:  0.37291842772612005\n",
      "n_estimators:  1  max_depth:  150 score:  0.364634404057481\n",
      "n_estimators:  1  max_depth:  200 score:  0.36877993801070724\n",
      "n_estimators:  1  max_depth:  250 score:  0.3711468019160327\n",
      "n_estimators:  5  max_depth:  1 score:  0.3090025359256129\n",
      "n_estimators:  5  max_depth:  10 score:  0.48742955762186535\n",
      "n_estimators:  5  max_depth:  50 score:  0.47318610876303185\n",
      "n_estimators:  5  max_depth:  100 score:  0.47498943364327983\n",
      "n_estimators:  5  max_depth:  150 score:  0.47318963088193866\n",
      "n_estimators:  5  max_depth:  200 score:  0.4731966751197521\n",
      "n_estimators:  5  max_depth:  250 score:  0.4726049591434208\n",
      "n_estimators:  10  max_depth:  1 score:  0.45555085939701334\n",
      "n_estimators:  10  max_depth:  10 score:  0.550503663003663\n",
      "n_estimators:  10  max_depth:  50 score:  0.5854289940828402\n",
      "n_estimators:  10  max_depth:  100 score:  0.6038250211327135\n",
      "n_estimators:  10  max_depth:  150 score:  0.5961080586080585\n",
      "n_estimators:  10  max_depth:  200 score:  0.5806530008453086\n",
      "n_estimators:  10  max_depth:  250 score:  0.5835974922513384\n",
      "n_estimators:  25  max_depth:  1 score:  0.5350450831220062\n",
      "n_estimators:  25  max_depth:  10 score:  0.6305719921104537\n",
      "n_estimators:  25  max_depth:  50 score:  0.6566638489715413\n",
      "n_estimators:  25  max_depth:  100 score:  0.6607847280924204\n",
      "n_estimators:  25  max_depth:  150 score:  0.6578261482107636\n",
      "n_estimators:  25  max_depth:  200 score:  0.6619928148774301\n",
      "n_estimators:  25  max_depth:  250 score:  0.6578296703296702\n",
      "n_estimators:  50  max_depth:  1 score:  0.5421386306001692\n",
      "n_estimators:  50  max_depth:  10 score:  0.6536876584953506\n",
      "n_estimators:  50  max_depth:  50 score:  0.6649584389969005\n",
      "n_estimators:  50  max_depth:  100 score:  0.6602035784728091\n",
      "n_estimators:  50  max_depth:  150 score:  0.6613834883065651\n",
      "n_estimators:  50  max_depth:  200 score:  0.6625774866159482\n",
      "n_estimators:  50  max_depth:  250 score:  0.6613905325443786\n",
      "n_estimators:  75  max_depth:  1 score:  0.5421386306001692\n",
      "n_estimators:  75  max_depth:  10 score:  0.6536876584953506\n",
      "n_estimators:  75  max_depth:  50 score:  0.6649584389969005\n",
      "n_estimators:  75  max_depth:  100 score:  0.6602035784728091\n",
      "n_estimators:  75  max_depth:  150 score:  0.6613834883065651\n",
      "n_estimators:  75  max_depth:  200 score:  0.6625774866159482\n",
      "n_estimators:  75  max_depth:  250 score:  0.6613905325443786\n",
      "n_estimators:  100  max_depth:  1 score:  0.5421386306001692\n",
      "n_estimators:  100  max_depth:  10 score:  0.6536876584953506\n",
      "n_estimators:  100  max_depth:  50 score:  0.6649584389969005\n",
      "n_estimators:  100  max_depth:  100 score:  0.6602035784728091\n",
      "n_estimators:  100  max_depth:  150 score:  0.6613834883065651\n",
      "n_estimators:  100  max_depth:  200 score:  0.6625774866159482\n",
      "n_estimators:  100  max_depth:  250 score:  0.6613905325443786\n",
      "best: 0.6649584389969005\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "for i in (1, 5, 10, 25, 50, 75, 100):\n",
    "    for j in (1, 10, 50, 100, 150, 200, 250):\n",
    "        model = RandomForestClassifier(n_estimators=j, max_depth = i, random_state=21)\n",
    "        scores = cross_val_score(model, features, target, scoring=\"accuracy\", cv=10)\n",
    "        print(\"n_estimators: \", i, \" max_depth: \", j, \"score: \", scores.mean())\n",
    "        if scores.mean() > best:\n",
    "            best=scores.mean()\n",
    "print(\"best:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289940828402367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=50, max_depth = 50, random_state=21)\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draws_barh(coefs, features, n, b=True):\n",
    "    if b==True:\n",
    "        cf = abs(coefs).sum(axis=0)\n",
    "    else:\n",
    "        cf = abs(coefs)\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    indices = cf.argsort()[::-1][:n]\n",
    "    ax.barh(np.arange(n), cf[indices], color=\"g\")\n",
    "    ax.set_yticks(np.arange(n))\n",
    "    ax.set_yticklabels(features[indices])\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draws_barh(model.feature_importances_, features.columns, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/rand_forest.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, \"../data/rand_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = joblib.load(\"../data/rand_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289940828402367"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_2.predict(X_test)\n",
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
